{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "f0aa3635-c781-463e-b9fe-54f4c90bde33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style=\"\n",
    "  background-color: #ffe6e6;\n",
    "  border: 2px solid #ff4d4d;\n",
    "  border-radius: 8px;\n",
    "  padding: 16px;\n",
    "  font-family: Arial, sans-serif;\n",
    "  color: #660000;\n",
    "\">\n",
    "  <h3 style=\"margin-top: 0; color: #b30000;\">⚠ This Demo is getting old!</h3>\n",
    "  <p>\n",
    "    Databricks is moving fast — it’s now easier than ever to deploy <strong>multi-agent systems</strong> \n",
    "    and run evals with <strong>MLflow 3.0</strong>.\n",
    "  </p>\n",
    "  <p>\n",
    "    Install <code>dbdemos</code> <strong>ai-agent</strong> demos to explore the latest features.<br>\n",
    "    <em>This content will be deprecated soon.</em>\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "6ff3808f-095f-4426-8258-02b53bbeb02c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 1/ Deploying our first RAG application with Mosaic AI Agent Framework & Agent Evaluation\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/rag-basic.png?raw=true\" style=\"width: 800px; margin-left: 10px\">\n",
    "\n",
    "<br/>\n",
    "\n",
    "## From data to chatbot in 10 minutes\n",
    "\n",
    "Rag applications are decoupled in 2 main parts:\n",
    "- The knowledge database used to add additional context and improve the bot answer\n",
    "- The actual chatbot application and its review / feedback mechanism\n",
    "\n",
    "## 1.1/ Data preparation for RAG: building and indexing our knowledge base into Databricks Vector Search\n",
    "\n",
    "Let's start by prepraing our knowledge database. In this simple first demo, we'll be using data from Databricks Documentation already prepared and chuncked.\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection or disable tracker during installation. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-science&org_id=341332174749405&notebook=%2F01-first-step%2F01-First-Step-RAG-On-Databricks&demo_name=llm-rag-chatbot&event=VIEW&path=%2F_dbdemos%2Fdata-science%2Fllm-rag-chatbot%2F01-first-step%2F01-First-Step-RAG-On-Databricks&version=1\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2bdfae9-27cc-435a-864b-0d5f68c4462c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U --quiet databricks-sdk==0.49.0 \"databricks-langchain>=0.4.0\" databricks-agents mlflow[databricks] databricks-vectorsearch==0.55 langchain==0.3.25 langchain_core==0.3.59 bs4==0.0.2 markdownify==0.14.1 pydantic==2.10.1\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d1ea66c-1033-425e-9098-4b4e3f60b356",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ../_resources/00-init $reset_all_data=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac2e1658-5565-44ed-9452-8869912edbf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "-- The dataset for your knowledge base has been loaded for you in the init notebook.\n",
    "SELECT * FROM databricks_documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "fefa179b-8596-41a5-bda0-110cd9d2e94a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## 1.2/ Vector search Endpoints\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/rag-basic-prep-2.png?raw=true\" style=\"float: right; margin-left: 10px\" width=\"400px\">\n",
    "\n",
    "Vector search endpoints are entities where your indexes will live. Think about them as entry point to handle your search request. \n",
    "\n",
    "Let's start by creating our first Vector Search endpoint. Once created, you can view it in the [Vector Search Endpoints UI](#/setting/clusters/vector-search). Click on the endpoint name to see all indexes that are served by the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "015b3fb8-641d-44f2-9dc0-ea5eaae4f622",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "vsc = VectorSearchClient(disable_notice=True)\n",
    "\n",
    "if not endpoint_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME):\n",
    "    vsc.create_endpoint(name=VECTOR_SEARCH_ENDPOINT_NAME, endpoint_type=\"STANDARD\")\n",
    "\n",
    "wait_for_vs_endpoint_to_be_ready(vsc, VECTOR_SEARCH_ENDPOINT_NAME)\n",
    "print(f\"Endpoint named {VECTOR_SEARCH_ENDPOINT_NAME} is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "4848bee7-5af2-4835-b8ab-16b69178f04e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/rag-basic-prep-3.png?raw=true\" style=\"float: right; margin-left: 10px\" width=\"400px\">\n",
    "\n",
    "\n",
    "## 1.3/ Creating the Vector Search Index\n",
    "\n",
    "Once the endpoint is created, all we now have to do is to as Databricks to create the index on top of the existing table. \n",
    "\n",
    "You just need to specify the text column and our embedding foundation model (`GTE`).  Databricks will build and synchronize the index automatically for us.\n",
    "\n",
    "This can be done using the API, or in a few clicks within the Unity Catalog Explorer menu:\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/index_creation.gif?raw=true\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7eaf41b-ccae-4ac4-9330-2611d2262d63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "import databricks.sdk.service.catalog as c\n",
    "\n",
    "#The table we'd like to index\n",
    "source_table_fullname = f\"{catalog}.{db}.databricks_documentation\"\n",
    "# Where we want to store our index\n",
    "vs_index_fullname = f\"{catalog}.{db}.databricks_documentation_vs_index\"\n",
    "\n",
    "if not index_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname):\n",
    "  print(f\"Creating index {vs_index_fullname} on endpoint {VECTOR_SEARCH_ENDPOINT_NAME}...\")\n",
    "  vsc.create_delta_sync_index(\n",
    "    endpoint_name=VECTOR_SEARCH_ENDPOINT_NAME,\n",
    "    index_name=vs_index_fullname,\n",
    "    source_table_name=source_table_fullname,\n",
    "    pipeline_type=\"TRIGGERED\",\n",
    "    primary_key=\"id\",\n",
    "    embedding_source_column='content', #The column containing our text\n",
    "    embedding_model_endpoint_name='databricks-gte-large-en' #The embedding endpoint used to create the embeddings\n",
    "  )\n",
    "  #Let's wait for the index to be ready and all our embeddings to be created and indexed\n",
    "  wait_for_index_to_be_ready(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname)\n",
    "else:\n",
    "  #Trigger a sync to update our vs content with the new data saved in the table\n",
    "  wait_for_index_to_be_ready(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname)\n",
    "  vsc.get_index(VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname).sync()\n",
    "\n",
    "print(f\"index {vs_index_fullname} on table {source_table_fullname} is ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f6ffdf8-6646-4480-81fa-ade982515b2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1.4/ Searching for relevant content\n",
    "\n",
    "That's all we have to do. Databricks will automatically capture and synchronize new entries in your table with the index.\n",
    "\n",
    "Note that depending on your dataset size and model size, index creation can take a few seconds to start and index your embeddings.\n",
    "\n",
    "Let's give it a try and search for similar content.\n",
    "\n",
    "*Note: `similarity_search` also support a filters parameter. This is useful to add a security layer to your RAG system: you can filter out some sensitive content based on who is doing the call (for example filter on a specific department based on the user preference).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0713df02-bf34-4a4b-b79b-93ee04c04a37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "question = \"How can I track billing usage on my account?\"\n",
    "\n",
    "results = vsc.get_index(VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname).similarity_search(\n",
    "  query_text=question,\n",
    "  columns=[\"url\", \"content\"],\n",
    "  num_results=1)\n",
    "docs = results.get('result', {}).get('data_array', [])\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "353c8635-2924-4e0e-84ac-b5fca78cb2a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2/ Deploy our chatbot model with RAG using DBRX\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/rag-basic-chain-1.png?raw=true\" style=\"float: right\" width=\"500px\">\n",
    "\n",
    "We've seen how Databricks makes it easy to ingest and prepare your documents, and deploy a Vector Search index on top of it with just clicks.\n",
    "\n",
    "Now that our Vector Searc index is ready, let's deploy a langchain application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0f86548-7fc1-486e-a98b-63a23f32d760",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2.1/ Configuring our Chain parameters\n",
    "\n",
    "As any appliaction, a RAG chain needs some configuration for each environement (ex: different catalog for test/prod environement). \n",
    "\n",
    "Databricks makes this easy with Chain Configurations. You can use this object to configure any value within your app, including the different system prompts and make it easy to test and deploy newer version with better prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76fdda4d-a12e-413e-977c-2b454f8955ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# For this first basic demo, we'll keep the configuration as a minimum. In real app, you can make all your RAG as a param (such as your prompt template to easily test different prompts!)\n",
    "chain_config = {\n",
    "    \"llm_model_serving_endpoint_name\": \"databricks-meta-llama-3-3-70b-instruct\",  # the foundation model we want to use\n",
    "    \"vector_search_endpoint_name\": VECTOR_SEARCH_ENDPOINT_NAME,  # the endoint we want to use for vector search\n",
    "    \"vector_search_index\": f\"{catalog}.{db}.databricks_documentation_vs_index\",\n",
    "    \"llm_prompt_template\": \"\"\"You are an assistant that answers questions. Use the following pieces of retrieved context to answer the question. Some pieces of context may be irrelevant, in which case you should not use them to form the answer.\\n\\nContext: {context}\"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "0202050b-0d81-419c-af06-847f17c930d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.2 Building our Langchain retriever\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/rag-basic-chain-2.png?raw=true\" style=\"float: right\" width=\"500px\">\n",
    "\n",
    "Let's start by building our Langchain retriever. \n",
    "\n",
    "It will be in charge of:\n",
    "\n",
    "* Creating the input question (our Managed Vector Search Index will compute the embeddings for us)\n",
    "* Calling the vector search index to find similar documents to augment the prompt with \n",
    "\n",
    "Databricks Langchain wrapper makes it easy to do in one step, handling all the underlying logic and API call for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c1513c4-1b11-40d1-aaa2-513788669bba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks_langchain.vectorstores import DatabricksVectorSearch\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "## Enable MLflow Tracing\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "## Load the chain's configuration\n",
    "model_config = mlflow.models.ModelConfig(development_config=chain_config)\n",
    "\n",
    "## Turn the Vector Search index into a LangChain retriever\n",
    "vector_search_as_retriever = DatabricksVectorSearch(\n",
    "    endpoint=model_config.get(\"vector_search_endpoint_name\"),\n",
    "    index_name=model_config.get(\"vector_search_index\"),\n",
    "    columns=[\"id\", \"content\", \"url\"],\n",
    ").as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Method to format the docs returned by the retriever into the prompt (keep only the text from chunks)\n",
    "def format_context(docs):\n",
    "    chunk_contents = [f\"Passage: {d.page_content}\\n\" for d in docs]\n",
    "    return \"\".join(chunk_contents)\n",
    "\n",
    "#Let's try our retriever chain:\n",
    "relevant_docs = (vector_search_as_retriever | RunnableLambda(format_context)| StrOutputParser()).invoke('How to start a Databricks cluster?')\n",
    "\n",
    "display_txt_as_html(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "f93526b9-14c9-453c-aff4-46ddafa62987",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You can see in the results that Databricks automatically trace your chain details and you can debug each steps and review the documents retrieved.\n",
    "\n",
    "## 2.3/ Building Databricks Chat Model to query our demo's Foundational LLM\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/rag-basic-chain-3.png?raw=true\" style=\"float: right\" width=\"500px\">\n",
    "\n",
    "Our chatbot will be using Meta's Llama open source model. However, it could be utilized with DBRX (_pictured_), or any other LLMs served on Databricks.  \n",
    "\n",
    "Other types of models that could be utilized include:\n",
    "\n",
    "- Databricks Foundation models (_what we will use by default in this demo_)\n",
    "- Your organization's custom, fine-tuned model\n",
    "- An external model provider (_such as Azure OpenAI_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51597ae1-c7b0-4645-bd1c-267eaa84f440",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from databricks_langchain.chat_models import ChatDatabricks\n",
    "from operator import itemgetter\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [  \n",
    "        (\"system\", model_config.get(\"llm_prompt_template\")), # Contains the instructions from the configuration\n",
    "        (\"user\", \"{question}\") #user's questions\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Our foundation model answering the final prompt\n",
    "model = ChatDatabricks(\n",
    "    endpoint=model_config.get(\"llm_model_serving_endpoint_name\"),\n",
    "    extra_params={\"temperature\": 0.01, \"max_tokens\": 500}\n",
    ")\n",
    "\n",
    "#Let's try our prompt:\n",
    "answer = (prompt | model | StrOutputParser()).invoke({'question':'How to start a Databricks cluster?', 'context': ''})\n",
    "display_txt_as_html(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "36a252da-d25a-4a04-a53c-aa7d8a56c2a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## 2.4/ Putting it together in a final chain, supporting the standard Chat Completion format\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/rag-basic-chain-4.png?raw=true\" style=\"float: right\" width=\"500px\">\n",
    "\n",
    "\n",
    "Let's now merge the retriever and the model in a single Langchain chain.\n",
    "\n",
    "We will use a custom langchain template for our assistant to give proper answer.\n",
    "\n",
    "We will make sure our chain support the standard Chat Completion API input schema : `{\"messages\": [{\"role\": \"user\", \"content\": \"What is Retrieval-augmented Generation?\"}]}`\n",
    "\n",
    "Make sure you take some time to try different templates and adjust your assistant tone and personality for your requirement.\n",
    "\n",
    "*Note that we won't support history in this first version, and will only take the last message as the question. See the advanced demo for a more complete example.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ab5c157-fea1-43f8-9920-dee7b9cd27e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Return the string contents of the most recent messages: [{...}] from the user to be used as input question\n",
    "def extract_user_query_string(chat_messages_array):\n",
    "    return chat_messages_array[-1][\"content\"]\n",
    "\n",
    "# RAG Chain\n",
    "chain = (\n",
    "    {\n",
    "        \"question\": itemgetter(\"messages\") | RunnableLambda(extract_user_query_string),\n",
    "        \"context\": itemgetter(\"messages\")\n",
    "        | RunnableLambda(extract_user_query_string)\n",
    "        | vector_search_as_retriever\n",
    "        | RunnableLambda(format_context),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "86ccc0ff-ab64-4675-9d90-71289aa57b1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Databricks will track all the chain for you\n",
    "\n",
    "<img src=\"https://ai-cookbook.io/_images/mlflow_trace2.gif\" width=\"600px\" style=\"float: right; margin-left: 10px\">\n",
    "\n",
    "As you can see in the cell result below, Databricks automatically trace the chain call. \n",
    "\n",
    "This makes it super easy to debug and improve your chain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ff98700-8019-40c8-a99e-825f0878f045",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's give it a try:\n",
    "input_example = {\"messages\": [ {\"role\": \"user\", \"content\": \"What is Retrieval-augmented Generation?\"}]}\n",
    "answer = chain.invoke(input_example)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22769f7a-cbff-46fa-b10f-c3ad00669217",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2.5/ Deploy a RAG Chain to a web-based UI for stakeholder feedback\n",
    "\n",
    "Our chain is now ready! \n",
    "\n",
    "Let's first register the Rag Chain model to MLFlow and Unity Catalog, and then use Agent Framework to deploy to the Agent Evaluation stakeholder review application which is backed by a scalable, production-ready Model Serving endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea272375-bcc2-41a3-9a0b-49da5356243f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Deploy the chain in Unity Catalog"
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models.resources import DatabricksVectorSearchIndex, DatabricksServingEndpoint\n",
    "# Log the model to MLflow\n",
    "with mlflow.start_run(run_name=\"basic_rag_bot\"):\n",
    "  logged_chain_info = mlflow.langchain.log_model(\n",
    "          #Note: In classical ML, MLflow works by serializing the model object.  In generative AI, chains often include Python packages that do not serialize.  Here, we use MLflow's new code-based logging, where we saved our chain under the chain notebook and will use this code instead of trying to serialize the object.\n",
    "          lc_model=os.path.join(os.getcwd(), 'chain'),  # Chain code file e.g., /path/to/the/chain.py \n",
    "          model_config=chain_config, # Chain configuration \n",
    "          artifact_path=\"chain\", # Required by MLflow, the chain's code/config are saved in this directory\n",
    "          input_example=input_example,\n",
    "          example_no_conversion=True,  # Required by MLflow to use the input_example as the chain's schema,\n",
    "          # Specify resources for automatic authentication passthrough\n",
    "          resources=[\n",
    "            DatabricksVectorSearchIndex(index_name=model_config.get(\"vector_search_index\")),\n",
    "            DatabricksServingEndpoint(endpoint_name=model_config.get(\"llm_model_serving_endpoint_name\"))\n",
    "          ]\n",
    "      )\n",
    "\n",
    "MODEL_NAME = \"basic_rag_demo\"\n",
    "MODEL_NAME_FQN = f\"{catalog}.{db}.{MODEL_NAME}\"\n",
    "# Register to UC\n",
    "uc_registered_model_info = mlflow.register_model(model_uri=logged_chain_info.model_uri, name=MODEL_NAME_FQN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b87ccb93-5093-4996-9316-863c3af010b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's now deploy the Mosaic AI **Agent Evaluation review application** using the model we just created!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c117bad-b77e-4fbe-9edf-60faf1d75e87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "# Deploy to enable the Review APP and create an API endpoint\n",
    "# Note: scaling down to zero will provide unexpected behavior for the chat app. Set it to false for a prod-ready application.\n",
    "deployment_info = agents.deploy(MODEL_NAME_FQN, model_version=uc_registered_model_info.version, scale_to_zero=True)\n",
    "\n",
    "instructions_to_reviewer = f\"\"\"## Instructions for Testing the Databricks Documentation Assistant chatbot\n",
    "\n",
    "Your inputs are invaluable for the development team. By providing detailed feedback and corrections, you help us fix issues and improve the overall quality of the application. We rely on your expertise to identify any gaps or areas needing enhancement.\"\"\"\n",
    "\n",
    "# Add the user-facing instructions to the Review App\n",
    "agents.set_review_instructions(MODEL_NAME_FQN, instructions_to_reviewer)\n",
    "\n",
    "wait_for_model_serving_endpoint_to_be_ready(deployment_info.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48aa4b56-dd37-45cb-9ede-7a4da9028b3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 3/ Use the Mosaic AI Agent Evaluation to evaluate your RAG applications\n",
    "\n",
    "## 3.1/ Chat with your bot and build your validation dataset!\n",
    "\n",
    "Our Chat Bot is now live. Databricks provides a built-in chatbot application that you can use to test the chatbot and give feedbacks on its answer.\n",
    "\n",
    "You can easily give access to external domain experts and have them test and review the bot.  **Your domain experts do NOT need to have Databricks Workspace access** - you can assign permissions to any user in your SSO if you have enabled [SCIM](https://docs.databricks.com/en/admin/users-groups/scim/index.html)\n",
    "\n",
    "This is a critical step to build or improve your evaluation dataset: have users ask questions to your bot, and provide the bot with output answer when they don't answer properly.\n",
    "\n",
    "Your Chatbot is automatically capturing all stakeholder questions and bot responses, including an MLflow trace for each, into Delta Tables in your Lakehouse. On top of that, Databricks makes it easy to track feedback from your end user: if the chatbot doesn't give a good answer and the user gives a thumbdown, their feedback is included in the Delta Tables.\n",
    "\n",
    "Once your eval dataset is ready, you'll then be able to leverage it for offline evaluation to measure your new chatbot performance, and also potentially to Fine Tune your model.\n",
    "<br/>\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/eval-framework.gif?raw=true\" width=\"1000px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b89343b-be28-49ae-90b4-ffc19d4620a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\n\\nReview App URL to share with your stakeholders: {deployment_info.review_app_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d671529-5e52-4eed-b62c-caa8c6487b29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## 3.2/ Evaluate your bot's quality with Mosaic AI Agent Evaluation specialized LLM judge models\n",
    "\n",
    "Our bot is now Live. \n",
    "\n",
    "Evaluation is a key part of deploying a RAG application. Databricks simplify this tasks with specialized LLM models tuned to evaluate your bot's quality/cost/latency, even if ground truth is not available.\n",
    "\n",
    "Mosaic AI Agent Evaluation evaluates:\n",
    "1. Answer correctness - requires ground truth\n",
    "2. Hallucination / groundness - no ground truth required\n",
    "3. Answer relevance - no ground truth required\n",
    "4. Retrieval precision - no ground truth required\n",
    "5. (Lack of) Toxicity - no ground truth required\n",
    "\n",
    "In this example, we'll use an evaluation set that we curated based on our internal experts using the Mosaic AI Agent Evaluation review app interface.  This proper Eval Dataset is saved as a Delta Table.\n",
    "\n",
    "To see how to collect the dataset from the Eval App, see the [03-advanced-app/03-Offline-Evaluation]($../03-advanced-app/03-Offline-Evaluation) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "296249b9-1c78-4dba-84b8-2724e7fd1e2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_dataset = spark.table(\"eval_set_databricks_documentation\").limit(10).toPandas()\n",
    "display(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8e0a249-0361-43b5-9d92-797bf1f7865e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.1/ Run Evaluation of your Chain\n",
    "\n",
    "Let's leverage the Mosaic AI Agent Evaluation specialized LLM to evaluate our model performance (make sure you use `databricks-rag`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68eaacba-dedf-4e9e-bc62-9993d4524cba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_id=logged_chain_info.run_id):\n",
    "    # Evaluate the logged model\n",
    "    eval_results = mlflow.evaluate(\n",
    "        data=eval_dataset,\n",
    "        model=logged_chain_info.model_uri,\n",
    "        model_type=\"databricks-agent\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "715e2841-7017-44a2-b46c-b61cee2528e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "You can open your MLFlow Experiment to review the different evaluation, and compare multiple model response to see how different prompts answer: \n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/rag-mlflow-eval.png?raw=true\" width=\"1200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "867b8642-d824-4ffb-bd44-c936927585b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next: Deep dive into details with a more complete chain\n",
    "\n",
    "This example was a simple demo. In the next set of notebooks, we'll go into more details and review how to prepare and split your documents, while working with more production-grade chain.\n",
    "\n",
    "We will also see how to deploy your [first Lakehouse Application]($../02-simple-app/03-Deploy-Frontend-Lakehouse-App) to deploy the Assistant to your end-users!\n",
    "\n",
    "Open the [../02-simple-app/01-Data-Preparation-and-Index]($../02-simple-app/01-Data-Preparation-and-Index) Notebook!\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "01-First-Step-RAG-On-Databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
