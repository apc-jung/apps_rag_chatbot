{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "36e6d26d-4e12-4ec6-b491-ad76cb69a2bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 1/ Data preparation for LLM Chatbot RAG\n",
    "\n",
    "## Building and indexing our knowledge base into Databricks Vector Search\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/llm-rag-managed-flow-1.png?raw=true\" style=\"float: right; width: 800px; margin-left: 10px\">\n",
    "\n",
    "In this notebook, we'll ingest our documentation pages and index them with a Vector Search index to help our chatbot provide better answers.\n",
    "\n",
    "Preparing high quality data is key for your chatbot performance. We recommend taking time to implement these next steps with your own dataset.\n",
    "\n",
    "Thankfully, Lakehouse AI provides state of the art solutions to accelerate your AI and LLM projects, and also simplifies data ingestion and preparation at scale.\n",
    "\n",
    "For this example, we will use Databricks documentation from [docs.databricks.com](docs.databricks.com):\n",
    "- Download the web pages\n",
    "- Split the pages in small chunks of text\n",
    "- Compute the embeddings using a Databricks Foundation model as part of our Delta Table\n",
    "- Create a Vector Search index based on our Delta Table  \n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection or disable tracker during installation. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-science&org_id=341332174749405&notebook=%2F02-simple-app%2F01-Data-Preparation-and-Index&demo_name=llm-rag-chatbot&event=VIEW&path=%2F_dbdemos%2Fdata-science%2Fllm-rag-chatbot%2F02-simple-app%2F01-Data-Preparation-and-Index&version=1\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b301697-b64b-4a9c-999a-7edd39875a5e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install required external libraries"
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet -U mlflow[databricks] lxml==4.9.3 transformers==4.49.0 langchain==0.3.25 databricks-vectorsearch==0.55 bs4==0.0.2 markdownify==0.14.1\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1e3bff8-74d1-44ae-b91f-aa10e6e69282",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Init our resources and catalog"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ../_resources/00-init $reset_all_data=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "e13d9760-8380-477c-a37c-75a82e1049dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Extracting Databricks documentation sitemap and pages\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/llm-rag-data-prep-1.png?raw=true\" style=\"float: right; width: 600px; margin-left: 10px\">\n",
    "\n",
    "First, let's create our raw dataset as a Delta Lake table.\n",
    "\n",
    "For this demo, we will directly download a few documentation pages from `docs.databricks.com` and save the HTML content.\n",
    "\n",
    "Here are the main steps:\n",
    "\n",
    "- Run a quick script to extract the page URLs from the `sitemap.xml` file\n",
    "- Download the web pages\n",
    "- Use BeautifulSoup to extract the ArticleBody\n",
    "- Save the HTML results in a Delta Lake table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdc35cfa-8020-42b9-b67f-d9a535542b9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS raw_documentation\")\n",
    "\n",
    "if not spark.catalog.tableExists(\"raw_documentation\") or spark.table(\"raw_documentation\").isEmpty():\n",
    "    # Download Databricks documentation to a DataFrame (see _resources/00-init for more details)\n",
    "    download_and_write_databricks_documentation_to_table(table_name=\"raw_documentation\")\n",
    "    # download_databricks_documentation_articles()\n",
    "\n",
    "display(spark.table(\"raw_documentation\").limit(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "68e5fec6-3b54-4f30-aef4-fe2b6366230d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Splitting documentation pages into small chunks\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/llm-rag-data-prep-2.png?raw=true\" style=\"float: right; width: 600px; margin-left: 10px\">\n",
    "\n",
    "LLM models typically have a maximum input context length, and you won't be able to compute embeddings for very long texts.\n",
    "In addition, the longer your context length is, the longer it will take for the model to provide a response.\n",
    "\n",
    "Document preparation is key for your model to perform well, and multiple strategies exist depending on your dataset:\n",
    "\n",
    "- Split document into small chunks (paragraph, h2...)\n",
    "- Truncate documents to a fixed length\n",
    "- The chunk size depends on your content and how you'll be using it to craft your prompt. Adding multiple small doc chunks in your prompt might give different results than sending only a big one\n",
    "- Split into big chunks and ask a model to summarize each chunk as a one-off job, for faster live inference\n",
    "- Create multiple agents to evaluate each bigger document in parallel, and ask a final agent to craft your answer...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "b654eae5-20b1-4319-8688-62fdbdad4ed2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Splitting our big documentation pages in smaller chunks (h2 sections)\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/chunk-window-size.png?raw=true\" style=\"float: right\" width=\"700px\">\n",
    "<br/>\n",
    "In this demo, we have big documentation articles, which are too long for the prompt to our model. \n",
    "\n",
    "We won't be able to use multiple documents as RAG context as they would exceed our max input size. Some recent studies also suggest that bigger window size isn't always better, as the LLMs seem to focus on the beginning and end of your prompt.\n",
    "\n",
    "In our case, we'll split these articles between HTML `h2` tags, remove HTML and ensure that each chunk is less than 500 tokens using LangChain. \n",
    "\n",
    "#### LLM Window size and Tokenizer\n",
    "\n",
    "The same sentence might return different tokens for different models. LLMs are shipped with a `Tokenizer` that you can use to count tokens for a given sentence (usually more than the number of words) (see [Hugging Face documentation](https://huggingface.co/docs/transformers/main/tokenizer_summary) or [OpenAI](https://github.com/openai/tiktoken))\n",
    "\n",
    "Make sure the tokenizer you'll be using here matches your model. Databricks DBRX Instruct uses the same tokenizer as GPT4. We'll be using the `transformers` library to count DBRX Instruct tokens with its tokenizer. This will also keep our document token size below our embedding max size (1024).\n",
    "\n",
    "<br/>\n",
    "<br style=\"clear: both\">\n",
    "<div style=\"background-color: #def2ff; padding: 15px;  border-radius: 30px; \">\n",
    "  <strong>Information</strong><br/>\n",
    "  Remember that the following steps are specific to your dataset. This is a critical part to building a successful RAG assistant.\n",
    "  <br/> Always take time to manually review the chunks created and ensure that they make sense and contain relevant information.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96466a2d-7783-4e4b-8625-d06f0dc49523",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Splitting our html pages in smaller chunks"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer, OpenAIGPTTokenizer\n",
    "\n",
    "max_chunk_size = 500\n",
    "\n",
    "tokenizer = OpenAIGPTTokenizer.from_pretrained(\"openai-gpt\")\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(tokenizer, chunk_size=max_chunk_size, chunk_overlap=50)\n",
    "md_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[(\"##\", \"header2\")])\n",
    "\n",
    "# Split on H2, but merge small h2 chunks together to avoid having too small chunks. \n",
    "def split_html_on_h2(html, min_chunk_size=20, max_chunk_size=500):\n",
    "    if not html:\n",
    "        return []\n",
    "    #removes b64 images captured in the md    \n",
    "    html = re.sub(r'data:image\\/[a-zA-Z]+;base64,[A-Za-z0-9+/=\\n]+', '', html, flags=re.MULTILINE)\n",
    "    chunks = []\n",
    "    previous_chunk = \"\"\n",
    "    for c in md_splitter.split_text(html):\n",
    "        content = c.metadata.get('header2', \"\") + \"\\n\" + c.page_content\n",
    "        if len(tokenizer.encode(previous_chunk + content)) <= max_chunk_size / 2:\n",
    "            previous_chunk += content + \"\\n\"\n",
    "        else:\n",
    "            chunks.extend(text_splitter.split_text(previous_chunk.strip()))\n",
    "            previous_chunk = content + \"\\n\"\n",
    "    if previous_chunk:\n",
    "        chunks.extend(text_splitter.split_text(previous_chunk.strip()))\n",
    "    return [c for c in chunks if len(tokenizer.encode(c)) > min_chunk_size]\n",
    "\n",
    "# Let's try our chunking function\n",
    "html = spark.table(\"raw_documentation\").limit(1).collect()[0]['text']\n",
    "split_html_on_h2(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d6f470c-2c36-4ef8-9bf9-bfebe8f7b6ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Creating the chunk and saving them to our Delta Table\n",
    "\n",
    "The last step is to apply our UDF all our documentation text and save them to our `databricks_documentation` table\n",
    "\n",
    "*Note that this part would typically be setup as a production-grade job, running as soon as a new documentation page is updated. <br/> This could be setup as a Delta Live Table pipeline to incrementally consume updates.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b98ab56e-be63-45d3-af2e-09b58c366406",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create the final databricks_documentation table containing chunks"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--Note that we need to enable Change Data Feed on the table to create the index\n",
    "CREATE TABLE IF NOT EXISTS databricks_documentation (\n",
    "  id BIGINT GENERATED BY DEFAULT AS IDENTITY,\n",
    "  url STRING,\n",
    "  content STRING\n",
    ") TBLPROPERTIES (delta.enableChangeDataFeed = true); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "516fca75-0f96-4849-b95a-f7f6fe64b0ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's create a user-defined function (UDF) to chunk all our documents with spark\n",
    "@pandas_udf(\"array<string>\")\n",
    "def parse_and_split(docs: pd.Series) -> pd.Series:\n",
    "    return docs.apply(split_html_on_h2)\n",
    "    \n",
    "(spark.table(\"raw_documentation\")\n",
    "      .filter('text is not null')\n",
    "      .repartition(30)\n",
    "      .withColumn('content', F.explode(parse_and_split('text')))\n",
    "      .drop(\"text\")\n",
    "      .write.mode('overwrite').saveAsTable(\"databricks_documentation\"))\n",
    "\n",
    "display(spark.table(\"databricks_documentation\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "49291414-4cee-4388-b675-b0fc6c7ecef0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## What's required for our Vector Search Index\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/databricks-vector-search-managed-type.png?raw=true\" style=\"float: right\" width=\"800px\">\n",
    "\n",
    "Databricks provides multiple types of vector search indexes:\n",
    "\n",
    "- **Managed embeddings**: you provide a text column and endpoint name and Databricks synchronizes the index with your Delta table  **(what we'll use in this demo)**\n",
    "- **Self Managed embeddings**: you compute the embeddings and save them as a field of your Delta Table, Databricks will then synchronize the index\n",
    "- **Direct index**: when you want to use and update the index without having a Delta Table\n",
    "\n",
    "In this demo, we will show you how to setup a **Managed Embeddings** index *(self managed embeddings are covered in the advanced demo).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "f767fd04-b0a1-437b-b82c-e2935c19ffcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Introducing Databricks GTE Embeddings Foundation Model endpoints\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/llm-rag-data-prep-4.png?raw=true\" style=\"float: right; width: 600px; margin-left: 10px\">\n",
    "\n",
    "Foundation Models are provided by Databricks, and can be used out-of-the-box.\n",
    "\n",
    "Databricks supports several endpoint types to compute embeddings or evaluate a model:\n",
    "- A **foundation model endpoint**, provided by Databricks (ex: DBRX, MPT, GTE). **This is what we'll be using in this demo.**\n",
    "- An **external endpoint**, acting as a gateway to an external model (ex: Azure OpenAI)\n",
    "- A **custom**, fined-tuned model hosted on Databricks model service\n",
    "\n",
    "Open the [Model Serving Endpoint page](/ml/endpoints) to explore and try the foundation models.\n",
    "\n",
    "For this demo, we will use the foundation model `GTE` (embeddings) and `DBRX` (chat). <br/><br/>\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/databricks-foundation-models.png?raw=true\" width=\"600px\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "404192eb-e17c-4116-ac40-f4fa696dbc12",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "What is an embedding"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.deployments\n",
    "deploy_client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "\n",
    "#Embeddings endpoints convert text into a vector (array of float). Here is an example using GTEgte:\n",
    "response = deploy_client.predict(endpoint=\"databricks-gte-large-en\", inputs={\"input\": [\"What is Apache Spark?\"]})\n",
    "embeddings = [e['embedding'] for e in response.data]\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "803e0a7a-8782-4a13-867a-9de3ea872729",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Creating our Vector Search Index with Managed Embeddings and GTE\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/llm-rag-data-prep-3.png?raw=true\" style=\"float: right; width: 600px; margin-left: 10px\">\n",
    "\n",
    "With Managed embeddings, Databricks will automatically compute the embeddings for us. This is the easier mode to get started with Databricks.\n",
    "\n",
    "A vector search index uses a **Vector search endpoint** to serve the embeddings (you can think about it as your Vector Search API endpoint).\n",
    "\n",
    "Multiple Indexes can use the same endpoint. \n",
    "\n",
    "Let's start by creating one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d32c3f9e-0802-4387-9d65-0cfa74de14cf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Creating the Vector Search endpoint"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "vsc = VectorSearchClient()\n",
    "\n",
    "if not endpoint_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME):\n",
    "    vsc.create_endpoint(name=VECTOR_SEARCH_ENDPOINT_NAME, endpoint_type=\"STANDARD\")\n",
    "\n",
    "wait_for_vs_endpoint_to_be_ready(vsc, VECTOR_SEARCH_ENDPOINT_NAME)\n",
    "print(f\"Endpoint named {VECTOR_SEARCH_ENDPOINT_NAME} is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "99c2b751-b8d1-4ee1-a868-f9f7b4265db1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/index_creation.gif?raw=true\" width=\"600px\" style=\"float: right\">\n",
    "\n",
    "You can view your endpoint on the [Vector Search Endpoints UI](#/setting/clusters/vector-search). Click on the endpoint name to see all indexes that are served by the endpoint.\n",
    "\n",
    "\n",
    "### Creating the Vector Search Index\n",
    "\n",
    "All we now have to do is to as Databricks to create the index. \n",
    "\n",
    "Because it's a managed embedding index, we just need to specify the text column and our embedding foundation model (`GTE`).  Databricks will compute the embeddings for us automatically.\n",
    "\n",
    "This can be done using the API, or in a few clicks within the Unity Catalog Explorer menu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89c3eea9-5a52-4dac-b561-ec8d7f711254",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create the managed vector search using our endpoint"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "import databricks.sdk.service.catalog as c\n",
    "\n",
    "#The table we'd like to index\n",
    "source_table_fullname = f\"{catalog}.{db}.databricks_documentation\"\n",
    "# Where we want to store our index\n",
    "vs_index_fullname = f\"{catalog}.{db}.databricks_documentation_vs_index\"\n",
    "\n",
    "if not index_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname):\n",
    "  print(f\"Creating index {vs_index_fullname} on endpoint {VECTOR_SEARCH_ENDPOINT_NAME}...\")\n",
    "  try:\n",
    "    vsc.create_delta_sync_index(\n",
    "      endpoint_name=VECTOR_SEARCH_ENDPOINT_NAME,\n",
    "      index_name=vs_index_fullname,\n",
    "      source_table_name=source_table_fullname,\n",
    "      pipeline_type=\"TRIGGERED\",\n",
    "      primary_key=\"id\",\n",
    "      embedding_source_column='content', #The column containing our text\n",
    "      embedding_model_endpoint_name='databricks-gte-large-en' #The embedding endpoint used to create the embeddings\n",
    "    )\n",
    "  except Exception as e:\n",
    "    display_quota_error(e, VECTOR_SEARCH_ENDPOINT_NAME)\n",
    "    raise e\n",
    "  #Let's wait for the index to be ready and all our embeddings to be created and indexed\n",
    "  wait_for_index_to_be_ready(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname)\n",
    "else:\n",
    "  #Trigger a sync to update our vs content with the new data saved in the table\n",
    "  wait_for_index_to_be_ready(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname)\n",
    "  vsc.get_index(VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname).sync()\n",
    "\n",
    "print(f\"index {vs_index_fullname} on table {source_table_fullname} is ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be49eefa-5387-4b1b-b8c2-8fd0e0d34b66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Searching for similar content\n",
    "\n",
    "That's all we have to do. Databricks will automatically capture and synchronize new entries in your Delta Live Table.\n",
    "\n",
    "Note that depending on your dataset size and model size, index creation can take a few seconds to start and index your embeddings.\n",
    "\n",
    "Let's give it a try and search for similar content.\n",
    "\n",
    "*Note: `similarity_search` also support a filters parameter. This is useful to add a security layer to your RAG system: you can filter out some sensitive content based on who is doing the call (for example filter on a specific department based on the user preference).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e49f03e-012b-4eac-a3a6-e0bc4fcee7ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.deployments\n",
    "deploy_client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "\n",
    "question = \"How can I track billing usage on my workspaces?\"\n",
    "\n",
    "results = vsc.get_index(VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname).similarity_search(\n",
    "  query_text=question,\n",
    "  columns=[\"url\", \"content\"],\n",
    "  num_results=1)\n",
    "docs = results.get('result', {}).get('data_array', [])\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebe5e6ec-654b-4b18-adec-21294016f311",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next step: Deploy our chatbot model with RAG using DBRX\n",
    "\n",
    "We've seen how Databricks Lakehouse AI makes it easy to ingest and prepare your documents, and deploy a Vector Search index on top of it with just a few lines of code and configuration.\n",
    "\n",
    "This simplifies and accelerates your data projects so that you can focus on the next step: creating your real-time chatbot endpoint with well-crafted prompt augmentation.\n",
    "\n",
    "Open the [02-Deploy-RAG-Chatbot-Model]($./02-Deploy-RAG-Chatbot-Model) notebook to create and deploy a chatbot endpoint."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6206649510520737,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01-Data-Preparation-and-Index",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
